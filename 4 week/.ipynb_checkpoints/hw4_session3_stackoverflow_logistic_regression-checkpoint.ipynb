{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"../../img/ods_stickers.jpg\">\n",
    "## Открытый курс по машинному обучению. Сессия № 3\n",
    "Автор материала: Павел Нестеров (@mephistopheies). Материал распространяется на условиях лицензии [Creative Commons CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/). Можно использовать в любых целях (редактировать, поправлять и брать за основу), кроме коммерческих, но с обязательным упоминанием автора материала."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> Домашняя работа №4\n",
    "## <center> Логистическая регрессия в задаче тегирования вопросов StackOverflow\n",
    "\n",
    "**Надо вывести формулы, где это просится (да, ручка и бумажка), заполнить код в клетках и выбрать ответы в [веб-форме](https://docs.google.com/forms/d/100c3Ek94UL-VRwXrN4lxCSnGjfJrl6Gc96G21DNCh4w).**\n",
    "\n",
    "## 0. Описание задачи\n",
    "\n",
    "В этой домашней работе мы с вами изучим и запрограммируем модель для прогнозирования тегов по тексту вопроса на базе многоклассовой логистической регрессии. В отличие от обычной постановки задачи классификации (multiclass), в данном случае один пример может принадлежать одновременно к нескольким классам (multilabel). Мы будем реализовывать онлайн-версию алгоритма multilabel-классификации.\n",
    "\n",
    "Мы будем использовать небольшую выборку из протеггированных вопросов с сайта StackOverflow размером в 125 тысяч примеров (около 150 Мб, скачайте по [этой](https://drive.google.com/open?id=0B4bl7YMqDnViYVo0V2FubFVhMFE) ссылке).\n",
    "\n",
    "PS: Можно показать, что такая реализация совсем не эффективная и проще было бы использовать векторизированные вычисления. Для данного датасета так и есть. Но на самом деле подобные реализации используются в жизни, но естественно, написаны они не на Python. Например, в онлайн-моделях прогнозирования [CTR](https://en.wikipedia.org/wiki/Click-through_rate) юзеру показывается баннер, затем в зависимости от наличия клика происходит обновление параметров модели. В реальной жизни параметров модели может быть несколько сотен миллионов, а у юзера из этих ста миллионов от силы сто или тысяча параметров отличны от нуля, векторизировать такие вычисления не очень эффективно. Обычно все это хранится в огромных кластерах в in-memory базах данных, а обработка пользователей происходит распределенно.\n",
    "\n",
    "PS2:\n",
    "- в процессе решения домашней работы вам придется работать с текстом, и у вас может возникнуть желание сделать очевидный препроцессинг, например привести все слова в нижний регистр, в-общем **этого делать не нужно, если не оговорено заранее в задании**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install watermark\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем версии используемых библиотек. Совпадут ли ответы в случае других версий - не гарантируется."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPython 3.6.4\n",
      "IPython 6.2.1\n",
      "\n",
      "numpy 1.14.0\n",
      "scipy 1.0.0\n",
      "pandas 0.22.0\n",
      "matplotlib 2.1.2\n",
      "sklearn 0.19.1\n",
      "\n",
      "compiler   : MSC v.1900 64 bit (AMD64)\n",
      "system     : Windows\n",
      "release    : 10\n",
      "machine    : AMD64\n",
      "processor  : AMD64 Family 21 Model 1 Stepping 2, AuthenticAMD\n",
      "CPU cores  : 4\n",
      "interpreter: 64bit\n",
      "Git hash   : b3734b4365bdc22cf904b5020dadc763b907aa9b\n"
     ]
    }
   ],
   "source": [
    "%watermark -v -m -p numpy,scipy,pandas,matplotlib,sklearn -g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\mocor\\anaconda3\\lib\\site-packages\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style(\"dark\")\n",
    "plt.rcParams['figure.figsize'] = 16, 12\n",
    "from tqdm import tqdm_notebook\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# поменяйте на свой путь\n",
    "DS_FILE_NAME = 'stackoverflow_sample_125k.tsv'\n",
    "TAGS_FILE_NAME = 'top10_tags.tsv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'javascript', 'c#', 'java', 'android', 'ios', 'python', 'html', 'c++', 'jquery', 'php'}\n"
     ]
    }
   ],
   "source": [
    "top_tags = []\n",
    "with open(TAGS_FILE_NAME, 'r') as f:\n",
    "    for line in f:\n",
    "        top_tags.append(line.strip())\n",
    "top_tags = set(top_tags)\n",
    "print(top_tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Многоклассовая логистическая регрессия\n",
    "\n",
    "Вспомним, как получается логистическая регрессия для двух классов $\\left\\{0, 1\\right\\}$, вероятность принадлежности объекта к классу $1$ выписывается по теореме Байеса:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = 1 \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right) + p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} \\\\\n",
    "&=& \\dfrac{1}{1 + e^{-a}} \\\\\n",
    "&=& \\sigma\\left(a\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\vec{x}$ – вектор признаков объекта\n",
    "- $\\sigma$ – обозначение функции логистического сигмоида при скалярном аргументе\n",
    "- $a = \\log \\frac{p\\left(\\vec{x} \\mid c = 1\\right)p\\left(c = 1\\right)}{p\\left(\\vec{x} \\mid c = 0\\right)p\\left(c = 0\\right)} = \\sum_{i=0}^M w_i x_i$ – это отношение мы моделируем линейной функцией от признаков объекта и параметров модели\n",
    "\n",
    "Данное выражение легко обобщить до множества из $K$ классов, изменится только знаменатель в формуле Байеса. Запишем вероятность принадлежности объекта к классу $k$:\n",
    "$$\\large \\begin{array}{rcl}\n",
    "p\\left(c = k \\mid \\vec{x}\\right) &=& \\dfrac{p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right)}{\\sum_{i=1}^K p\\left(\\vec{x} \\mid c = i\\right)p\\left(c = i\\right)} \\\\\n",
    "&=& \\dfrac{e^{z_k}}{\\sum_{i=1}^{K}e^{z_i}} \\\\\n",
    "&=& \\sigma_k\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "где:\n",
    "- $\\sigma_k$ – обозначение функции softmax при векторном аргументе\n",
    "- $z_k = \\log p\\left(\\vec{x} \\mid c = k\\right)p\\left(c = k\\right) = \\sum_{i=0}^M w_{ki} x_i$ – это выражение моделируется линейной функцией от признаков объекта и параметров модели для класса $k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для моделирования полного правдоподобия примера мы используем [категориальное распределение](https://en.wikipedia.org/wiki/Categorical_distribution), а лучше его логарифм (для удобства):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\mathcal{L} = \\log p\\left({\\vec{x}}\\right) &=& \\log \\prod_{i=1}^K \\sigma_i\\left(\\vec{z}\\right)^{y_i} \\\\\n",
    "&=& \\sum_{i=1}^K y_i \\log \\sigma_i\\left(\\vec{z}\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "Получается хорошо знакомая нам функция [cross entropy](https://en.wikipedia.org/wiki/Cross_entropy) (если домножить на $-1$). Правдоподобие нужно максимизировать, а, соответственно, перекрестную энтропию нужно минимизировать. Продифференцировав по параметрам модели, мы _легко_ получим правила обновления весов для градиентного спуска, **проделайте этот вывод, если вы его не делали** (если вы вдруг сдались, то на [этом](https://www.youtube.com/watch?v=-WiR16raQf4) видео есть разбор вывода, понимание этого вам понадобится для дальнейшего выполнения задания; если предпочитаете текст, то и он есть [тут](https://www.ics.uci.edu/~pjsadows/notes.pdf) и [тут](https://eli.thegreenplace.net/2016/the-softmax-function-and-its-derivative/)):\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} &=& x_m \\left(y_k - \\sigma_k\\left(\\vec{z}\\right)\\right)\n",
    "\\end{array}$$\n",
    "\n",
    "В стандартной формулировке получается, что вектор $\\left(\\sigma_1, \\sigma_2, \\ldots, \\sigma_K\\right)$ образует дискретное вероятностное распределение, т.е. $\\sum_{i=1}^K \\sigma_i = 1$. Но в нашей постановке задачи каждый пример может иметь несколько тегов или одновременно принадлежать к нескольким классам. Для этого мы немного изменим модель:\n",
    "- будем считать, что все теги независимы друг от друга, т.е. каждый исход – это логистическая регрессия на два класса (либо есть тег, либо его нет), тогда вероятность наличия тега у примера запишется следующим образом (каждый тег/класс как и в многоклассовой логрегрессии имеет свой набор параметров):\n",
    "$$\\large p\\left(\\text{tag}_k \\mid \\vec{x}\\right) = \\sigma\\left(z_k\\right) = \\sigma\\left(\\sum_{i=1}^M w_{ki} x^i \\right)$$\n",
    "- наличие каждого тега мы будем моделировать с помощью <a href=\"https://en.wikipedia.org/wiki/Bernoulli_distribution\">распределения Бернулли</a>\n",
    "\n",
    "<font color=\"red\">Вопрос 1.</font> Ваше первое задание –  записать упрощенное выражение логарифма правдоподобия примера с признаками $\\vec{x}$. Как правило, многие алгоритмы оптимизации имеют интерфейс для минимизации функции, мы последуем этой же традиции и домножим полученное выражение на $-1$, а во второй части выведем формулы для минимизации полученного выражения."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. $\\large -\\mathcal{L} = -\\sum_{i=1}^M y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$\n",
    "2. $\\large -\\mathcal{L} = -\\sum_{i=1}^K y_i \\log \\sigma\\left(z_i\\right) + \\left(1 - y_i\\right) \\log \\left(1 - \\sigma\\left(z_i\\right)\\right)$ +\n",
    "3. $\\large -\\mathcal{L} = -\\sum_{i=1}^K z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$\n",
    "4. $\\large -\\mathcal{L} = -\\sum_{i=1}^M z_i \\log \\sigma\\left(y_i\\right) + \\left(1 - z_i\\right) \\log \\left(1 - \\sigma\\left(y_i\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Вывод формулы обновления весов\n",
    "\n",
    "<font color=\"red\">Вопрос 2.</font>В качестве второго задания вам предоставляется возможность вывести формулу градиента для $-\\mathcal{L}$. Какой вид она будет иметь?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(\\sigma\\left(z_k\\right) - y_k\\right)$\n",
    "2. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = -x_m \\left(y_k - \\sigma\\left(z_k\\right)\\right)$ +\n",
    "3. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(\\sigma\\left(z_k\\right)x_m - y_k\\right)$\n",
    "4. $\\large -\\frac{\\partial \\mathcal{L}}{\\partial w_{km}} = \\left(y_k - \\sigma\\left(z_k\\right)x_m\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Реализация базовой модели\n",
    "\n",
    "Вам предлагается каркас класса модели, разберите его внимательно, обращайте внимание на комментарии. Затем заполните пропуски, запустите полученную модель и ответьте на проверочный вопрос.\n",
    "\n",
    "Как вы могли уже заметить, при обновлении веса $w_{km}$ используется значение признака $x_m$, который равен $0$, если слова с индексом $m$ нет в предложении, и больше нуля, если такое слово есть. В нашем случае, чтобы не пересчитывать [bag-of-words](https://en.wikipedia.org/wiki/Bag-of-words_model) самим или с помощью [sklearn.feature_extraction.text.CountVectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html#sklearn.feature_extraction.text.CountVectorizer), мы будем идти по словам предложения в порядке их следования. Если какое-то слово встречается несколько раз, то мы добавляем его в аккумулятор со своим весом. В итоге получится то же самое, как если сначала посчитать количество одинаковых слов и домножить на соответствующий вес. Соответственно, при вычислении линейной комбинации $z$ весов модели и признаков примера необходимо учитывать только ненулевые признаки объекта.\n",
    "\n",
    "Подсказка:\n",
    "- если реализовывать вычисление сигмоида так же, как в формуле, то при большом отрицательном значении $z$ вычисление $e^{-z}$ превратится в очень большое число, которое вылетит за допустимые пределы\n",
    "- в то же время $e^{-z}$ от большого положительного $z$ будет нулем\n",
    "- воспользуйтесь свойствами функции $\\sigma$ для того, чтобы пофиксить эту ошибку и реализовать $\\sigma$ без риска overflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if z >= 0 : \n",
    "                        sigma = 1 / (1 + np.exp(-z))                                            \n",
    "                    else : \n",
    "                        sigma = 1 - 1/(1 + np.exp(z))\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if y == 1:\n",
    "                        sample_loss += -y*np.log(np.max([tolerance, sigma])) \n",
    "                    else:\n",
    "                        sample_loss+= -(1 - y)*np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22609ef67ac043cd9c2b691d8d29dc53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создадим эксемпляр модели и пройдемся по датасету\n",
    "model = LogRegressor()\n",
    "model.iterate_file()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проверим, действительно ли значение отрицательного логарифмического правдоподобия уменьшалось. Так как мы используем стохастический градентный спуск, не стоит ожидать плавного падения функции ошибки. Мы воспользуемся скользящим средним с окном в 10 тысяч примеров, чтобы хоть как-то сгладить график."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17ce9fbafd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean of the loss function on the last 10k train samples: 20.05\n"
     ]
    }
   ],
   "source": [
    "print('Mean of the loss function on the last 10k train samples: %0.2f' % np.mean(model._loss[-35000:-25000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 3.</font>\n",
    "Вычислите среднее значение функции стоимости на последних 10 000 примеров тренировочного набора, к какому из значений ваш ответ ближе всего?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 17.54\n",
    "2. 18.64\n",
    "3. <b>19.74</b>\n",
    "4. 20.84"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4. Тестирование модели\n",
    "\n",
    "В базовой модели первые 100 000 строк используются для обучения, а оставшиеся – для тестирования. Как вы можете заметить, значение отрицательного логарифмического правдоподобия не очень информативно, хоть и позволяет сравнивать разные модели. В качестве четвертого задания вам необходимо модифицировать базовую модель таким образом, чтобы метод `iterate_file` возвращал значение _точности_ на тестовой части набора данных. \n",
    "\n",
    "Точность определим следующим образом:\n",
    "- считаем, что тег у вопроса присутствует, если спрогнозированная вероятность тега больше 0.9\n",
    "- точность одного примера расчитывается как [коэффициент Жаккара](https://ru.wikipedia.org/wiki/Коэффициент_Жаккара) между множеством настоящих тегов и предсказанных моделью\n",
    "  - например, если у примера настоящие теги ['html', 'jquery'], а по версии модели ['ios', 'html', 'java'], то коэффициент Жаккара будет равен |['html', 'jquery'] $\\cap$ ['ios', 'html', 'java']| / |['html', 'jquery'] $\\cup$ ['ios', 'html', 'java']| = |['html']| / |['jquery', 'ios', 'html', 'java']| = 1/4\n",
    "- метод `iterate_file` возвращает **среднюю** точность на тестовом наборе данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь\n",
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        \n",
    "        accuracy_list = []\n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                good_tags=[]\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "   \n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "    \n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if z >= 0 : \n",
    "                        sigma = 1 / (1 + np.exp(-z))                                            \n",
    "                    else : \n",
    "                        sigma = 1 - 1/(1 + np.exp(z))\n",
    "    \n",
    "                    \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if y == 1:\n",
    "                        sample_loss += -y*np.log(np.max([tolerance, sigma])) \n",
    "                    else:\n",
    "                        sample_loss+= -(1 - y)*np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= -learning_rate*dLdw\n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    else:\n",
    "                        if sigma > 0.9:\n",
    "                            good_tags.append(tag)\n",
    "                            \n",
    "                if (n > top_n_train):\n",
    "                    accuracy = len(tags.intersection(good_tags))/len(tags.union(good_tags))\n",
    "                    accuracy_list.append(accuracy)\n",
    "                    \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "            return np.mean(accuracy_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56e5d73f860247d6b0698bf5897e77ca",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.59\n"
     ]
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "# выведем полученное значение с точностью до двух знаков\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 4.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.39\n",
    "2. 0.49\n",
    "3. <b>0.59</b>\n",
    "4. 0.69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 5. $L_2$-регуляризация\n",
    "\n",
    "В качестве пятого задания вам необходимо добавить в класс `LogRegressor` поддержку $L_2$-регуляризации. В методе `iterate_file` должен появиться параметр `lmbda=0.01` со значением по умолчанию. С учетом регуляризации новая функция стоимости примет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\frac{\\lambda}{2} \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2\n",
    "\\end{array}$$\n",
    "\n",
    "Градиент первого члена суммы мы уже вывели, а для второго он имеет вид:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "\\frac{\\partial}{\\partial w_{ki}} \\frac{\\lambda}{2} R\\left(W\\right) &=& \\lambda w_{ki}\n",
    "\\end{array}$$\n",
    "\n",
    "Если мы на каждом примере будем делать честное обновление всех весов, то все очень замедлится, ведь нам придется на каждой итерации пробегать по всем словам словаря. В ущерб теоретической корректности мы используем грязный трюк: будем регуляризировать только те слова, которые присутствуют в текущем предложении. Не забывайте, что смещение (bias) не регуляризируется. `sample_loss` тоже должен остаться без изменений.\n",
    "\n",
    "Замечание:\n",
    "- не забудьте, что нужно учитывать регуляризацию слова в градиентном шаге только один раз\n",
    "- условимся, что учитываем регуляризацию только при первой встрече слова\n",
    "- если бы мы считали сначала bag-of-words, то мы бы в цикле шли по уникальным словам, но т.к. мы этого не делаем, приходится выкручиваться (еще одна жертва богу online-моделей)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.01):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        accuracy_list = []\n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                good_tags=[]\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if z >= 0 : \n",
    "                        sigma = 1 / (1 + np.exp(-z))                                            \n",
    "                    else : \n",
    "                        sigma = 1 - 1/(1 + np.exp(z))\n",
    "                           \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if y == 1:\n",
    "                        sample_loss += -y * np.log(np.max([tolerance, sigma]))          \n",
    "                    else:\n",
    "                        sample_loss+= -(1 - y)*np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                       \n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= learning_rate * (-dLdw + lmbda * self._w[tag][self._vocab[word]])   \n",
    "                        self._b[tag] -= -learning_rate * dLdw\n",
    "                    if sigma > 0.9:\n",
    "                        good_tags.append(tag)\n",
    "                \n",
    "                else:\n",
    "                    if (n > top_n_train):\n",
    "                        accuracy = len(tags.intersection(good_tags)) / len(tags.union(good_tags))\n",
    "                        accuracy_list.append(accuracy)\n",
    "                                        \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "                \n",
    "            return(np.mean(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01c0b0dec2ee414d82852a0ddb9f1983",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17cdc388748>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 5.</font> К какому значению ближе всего полученное значение точности?\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.3\n",
    "2. 0.35\n",
    "3. 0.4\n",
    "4. <b>0.52</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ElasticNet регуляризация, вывод\n",
    "Помимо $L_2$ регуляризации, часто используется $L_1$ регуляризация.\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\frac{\\lambda}{2} R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right|\n",
    "\\end{array}$$\n",
    "\n",
    "Если линейно объединить $L_1$ и $L_2$ регуляризацию, то полученный тип регуляризации называется ElasticNet:\n",
    "\n",
    "$$\\large \\begin{array}{rcl}\n",
    "L &=& -\\mathcal{L} + \\lambda R\\left(W\\right) \\\\\n",
    "&=& -\\mathcal{L} + \\lambda \\left(\\gamma \\sum_{k=1}^K\\sum_{i=1}^M w_{ki}^2 + \\left(1 - \\gamma\\right) \\sum_{k=1}^K\\sum_{i=1}^M \\left|w_{ki}\\right| \\right)\n",
    "\\end{array}$$\n",
    "- где $\\gamma \\in \\left[0, 1\\right]$\n",
    "\n",
    "В качестве шестого вопроса вам предлагается вывести формулу градиента ElasticNet регуляризации (не учитывая $-\\mathcal{L}$). \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>:\n",
    "1. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) w_{ki}\\right)$ \n",
    "2. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma \\left|w_{ki}\\right| + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$\n",
    "3. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(2 \\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$ +\n",
    "4. $\\large \\frac{\\partial}{\\partial w_{ki}} \\lambda R\\left(W\\right) = \\lambda \\left(\\gamma w_{ki} + \\left(1 - \\gamma\\right) \\text{sign}\\left(w_{ki}\\right)\\right)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Регуляризация ElasticNet , реализация\n",
    "\n",
    "В качестве седьмой задачи вам предлается изменить класс `LogRegressor` таким образом, чтобы метод `iterate_file` принимал два параметра со значениями по умолчанию `lmbda=0.0002` и `gamma=0.1`. Сделайте один проход по датасету с включенной `ElasticNet`-регуляризацией и заданными значениями по умолчанию и ответьте на вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogRegressor():\n",
    "    \n",
    "    \"\"\"Конструктор\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    tags : list of string, default=top_tags\n",
    "        список тегов\n",
    "    \"\"\"\n",
    "    def __init__(self, tags=top_tags):      \n",
    "        # словарь который содержит мапинг слов предложений и тегов в индексы (для экономии памяти)\n",
    "        # пример: self._vocab['exception'] = 17 означает что у слова exception индекс равен 17\n",
    "        self._vocab = {}\n",
    "        \n",
    "        # параметры модели: веса\n",
    "        # для каждого класса/тега нам необходимо хранить собственный вектор весов\n",
    "        # по умолчанию у нас все веса будут равны нулю\n",
    "        # мы заранее не знаем сколько весов нам понадобится\n",
    "        # поэтому для каждого класса мы сосздаем словарь изменяемого размера со значением по умолчанию 0\n",
    "        # пример: self._w['java'][self._vocab['exception']]  содержит вес для слова exception тега java\n",
    "        self._w = dict([(t, defaultdict(int)) for t in tags])\n",
    "        \n",
    "        # параметры модели: смещения или вес w_0\n",
    "        self._b = dict([(t, 0) for t in tags])\n",
    "        \n",
    "        self._tags = set(tags)\n",
    "    \n",
    "    \"\"\"Один прогон по датасету\n",
    "    \n",
    "    Параметры\n",
    "    ----------\n",
    "    fname : string, default=DS_FILE_NAME\n",
    "        имя файла с данными\n",
    "        \n",
    "    top_n_train : int\n",
    "        первые top_n_train строк будут использоваться для обучения, остальные для тестирования\n",
    "        \n",
    "    total : int, default=10000000\n",
    "        информация о количестве строк в файле для вывода прогресс бара\n",
    "    \n",
    "    learning_rate : float, default=0.1\n",
    "        скорость обучения для градиентного спуска\n",
    "        \n",
    "    tolerance : float, default=1e-16\n",
    "        используем для ограничения значений аргумента логарифмов\n",
    "    \"\"\"\n",
    "    def iterate_file(self, \n",
    "                     fname=DS_FILE_NAME, \n",
    "                     top_n_train=100000, \n",
    "                     total=125000,\n",
    "                     learning_rate=0.1,\n",
    "                     tolerance=1e-16,\n",
    "                     lmbda=0.0002,\n",
    "                     gamma=0.1):\n",
    "        \n",
    "        self._loss = []\n",
    "        n = 0\n",
    "        accuracy_list = []\n",
    "        # откроем файл\n",
    "        with open(fname, 'r') as f:            \n",
    "            \n",
    "            # прогуляемся по строкам файла\n",
    "            for line in tqdm_notebook(f, total=total, mininterval=1):\n",
    "                good_tags=[]\n",
    "                pair = line.strip().split('\\t')\n",
    "                if len(pair) != 2:\n",
    "                    continue                \n",
    "                sentence, tags = pair\n",
    "                # слова вопроса, это как раз признаки x\n",
    "                sentence = sentence.split(' ')\n",
    "                # теги вопроса, это y\n",
    "                tags = set(tags.split(' '))\n",
    "                \n",
    "                # значение функции потерь для текущего примера\n",
    "                sample_loss = 0\n",
    "\n",
    "                # прокидываем градиенты для каждого тега\n",
    "                for tag in self._tags:\n",
    "                    # целевая переменная равна 1 если текущий тег есть у текущего примера\n",
    "                    y = int(tag in tags)\n",
    "                    \n",
    "                    # расчитываем значение линейной комбинации весов и признаков объекта\n",
    "                    # инициализируем z\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    z = self._b[tag]\n",
    "                    for word in sentence:\n",
    "                        # если в режиме тестирования появляется слово которого нет в словаре, то мы его игнорируем\n",
    "                        if n >= top_n_train and word not in self._vocab:\n",
    "                            continue\n",
    "                        if word not in self._vocab:\n",
    "                            self._vocab[word] = len(self._vocab)\n",
    "                        z += self._w[tag][self._vocab[word]]\n",
    "                    # вычисляем вероятность наличия тега\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if z >= 0 : \n",
    "                        sigma = 1 / (1 + np.exp(-z))                                            \n",
    "                    else : \n",
    "                        sigma = 1 - 1/(1 + np.exp(z))\n",
    "                           \n",
    "                    # обновляем значение функции потерь для текущего примера\n",
    "                    # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                    if y == 1:\n",
    "                        sample_loss += -y*np.log(np.max([tolerance, sigma]))\n",
    "                       \n",
    "                    else:\n",
    "                        sample_loss+= -(1 - y)*np.log(1 - np.min([1 - tolerance, sigma]))\n",
    "                       \n",
    "                 \n",
    "                    \n",
    "                    # если мы все еще в тренировочной части, то обновим параметры\n",
    "                    if n < top_n_train:\n",
    "                        # вычисляем производную логарифмического правдоподобия по весу\n",
    "                        # ЗАПОЛНИТЕ ПРОПУСКИ В КОДЕ\n",
    "                        dLdw = y - sigma\n",
    "\n",
    "                        # делаем градиентный шаг\n",
    "                        # мы минимизируем отрицательное логарифмическое правдоподобие (второй знак минус)\n",
    "                        # поэтому мы идем в обратную сторону градиента для минимизации (первый знак минус)\n",
    "                        for word in sentence:                        \n",
    "                            self._w[tag][self._vocab[word]] -= learning_rate *(-dLdw + 2 * lmbda * gamma * self._w[tag][self._vocab[word]] + lmbda * (1 - gamma) * np.sign(self._w[tag][self._vocab[word]]))   \n",
    "                        self._b[tag] -= -learning_rate*dLdw\n",
    "                    if sigma > 0.9:\n",
    "                        good_tags.append(tag)\n",
    "                \n",
    "                else:\n",
    "                    if (n > top_n_train):\n",
    "                        accuracy = len(tags.intersection(good_tags)) / len(tags.union(good_tags))\n",
    "                        accuracy_list.append(accuracy)\n",
    "                                        \n",
    "                n += 1\n",
    "                        \n",
    "                self._loss.append(sample_loss)\n",
    "                \n",
    "                \n",
    "            return(np.mean(accuracy_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "461a129569d6439695f36a09b8369e2c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=125000), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0.57\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17cdbf86d68>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file()\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 7.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. <b>0.59</b>\n",
    "2. 0.69\n",
    "3. 0.79\n",
    "4. 0.82"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Самые важные слова для тега\n",
    "\n",
    "Прелесть линейных моделей в том, что они легко интерпретируемы. Вам предлагается вычислить, какие слова вносят наибольший вклад в вероятность появления каждого из тегов. А затем ответьте на контрольный вопрос."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model._vocab_inv = dict([(v, k) for (k, v) in model._vocab.items()])\n",
    "\n",
    "for tag in model._tags:\n",
    "    print(tag, ':', ', '.join([model._vocab_inv[k] for (k, v) in \n",
    "                               sorted(model._w[tag].items(), \n",
    "                                      key=lambda t: t[1], \n",
    "                                      reverse=True)[:5]]))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 8.</font> Для многих тегов наличие самого тега в предложении является важным сигналом, у многих сам тег является самым сильным сигналом, что не удивительно. Для каких из тегов само название тега не входит в топ-5 самых важных?\n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. c# \n",
    "2. javascript\n",
    "3. jquery\n",
    "4. android"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 9. Сокращаем размер словаря\n",
    "Сейчас количество слов в словаре – 519290, если бы это была выборка из 10 миллионов вопросов с сайта StackOverflow, то размер словаря был бы миллионов 10. Регуляризировать модель можно не только изящно математически, но и топорно, например, ограничить размер словаря. Вам предоставляется возможность внести следующие изменения в класс `LogRegressor`:\n",
    "- добавить в метод `iterate_file` еще один аргумент со значением по умолчанию `update_vocab=True`\n",
    "- при `update_vocab=True` разрешать добавлять слова в словарь в режиме обучения\n",
    "- при `update_vocab=False` игнорировать слова не из словаря\n",
    "- добавить в класс метод `filter_vocab(n=10000)`, который оставит в словаре только топ-n самых популярных слов, используя данные из ``train``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# оставим только топ 10 000 слов\n",
    "model.filter_vocab(n=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# сделаем еще одну итерацию по датасету, уменьшив скорость обучения в 10 раз\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)\n",
    "plt.plot(pd.Series(model._loss[:-25000]).rolling(10000).mean());"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<font color=\"red\">Вопрос 9.</font> К какому значению ближе всего полученное значение точности:\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. 0.48\n",
    "2. 0.58\n",
    "3. 0.68\n",
    "4. 0.78"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Прогнозирование тегов для новых вопросов\n",
    "\n",
    "В завершение этого задания вам предлагается реализовать метод `predict_proba`, который принимает строку, содержащую вопрос, а возвращает список предсказанных тегов вопроса с их вероятностями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Обновите определение класса LogRegressor\n",
    "# Ваш код здесь"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogRegressor()\n",
    "acc = model.iterate_file(update_vocab=True)\n",
    "print('%0.2f' % acc)\n",
    "model.filter_vocab(n=10000)\n",
    "acc = model.iterate_file(update_vocab=False, learning_rate=0.01)\n",
    "print('%0.2f' % acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentence = (\"I want to improve my coding skills, so I have planned write \" +\n",
    "            \"a Mobile Application.need to choose between Apple's iOS or Google's Android.\" +\n",
    "            \" my background: I have done basic programming in .Net,C/C++,Python and PHP \" +\n",
    "            \"in college, so got OOP concepts covered. about my skill level, I just know \" +\n",
    "            \"concepts and basic syntax. But can't write complex applications, if asked :(\" +\n",
    "            \" So decided to hone my skills, And I wanted to know which is easier to \" +\n",
    "            \"learn for a programming n00b. A) iOS which uses Objective C B) Android \" + \n",
    "            \"which uses Java. I want to decide based on difficulty \" + \n",
    "            \"level\").lower().replace(',', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sorted(model.predict_proba(sentence).items(), \n",
    "       key=lambda t: t[1], reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color=\"red\">Вопрос 10.</font> Отметьте все теги, ассоциирующиеся с данным вопросом, если порог принятия равен $0.9$. То есть считаем, что вопросу надо поставить некоторый тег, если вероятность его появления, предсказанная моделью, больше или равна 0.9. \n",
    "\n",
    "<font color=\"red\">Варианты ответа:</font>\n",
    "1. android\n",
    "2. ios\n",
    "3. php\n",
    "4. java"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
